


# Saltzer & Schroeder for 2030: Security engineering principles in a world of AI
https://arxiv.org/pdf/2407.05710


# Saltzer & Schroeder для 2030: Принципи інженерії безпеки у світі штучного інтелекту

## АНОТАЦІЯ

Написання безпечного коду є складним завданням, тому очікується, що після випуску інструментів генерування коду на основі ШІ, таких як ChatGPT та GitHub Copilot, розробники будуть використовувати ці інструменти для виконання завдань безпеки та використання API безпеки. Однак чи є код, згенерований ChatGPT, безпечним? Як звичайний програмний інженер або інженер з безпеки зможе це визначити?

Наближаючись до наступного десятиліття, ми очікуємо більшого впровадження інструментів генерування коду на основі ШІ та бачимо, як розробники використовують їх для написання безпечного коду. Готуючись до цього, нам потрібно забезпечити безпеку за замовчуванням (security-by-design). У цій статті ми озираємося назад у часі на принципи проектування безпеки Saltzer & Schroeder, оскільки вони повинні будуть еволюціонувати та адаптуватися до викликів, які приходять зі світом коду, згенерованого штучним інтелектом.

## КЛЮЧОВІ СЛОВА

Принципи проектування безпеки, ChatGPT, великі мовні моделі

## ПОСИЛАННЯ ACM

Nikhil Patnaik, Joseph Hallett, та Awais Rashid. 2024. Saltzer & Schroeder для 2030: Принципи інженерії безпеки у світі ШІ. У Збірнику Міжнародного семінару з програмної інженерії в 2030 (SE 2030). ACM, Нью-Йорк, Нью-Йорк, США, 5 сторінок. https://doi.org/10.1145/nnnnnnn.nnnnnnn

## 1. ВСТУП

У 1974 році Saltzer розглянув виклик захисту та контролю обміну інформацією в Multics (Multiplexed Information and Computing Service) [26]. Saltzer запропонував 5 принципів проектування для допомоги в оцінці різних рішень. Ці принципи проектування розглядали списки контролю доступу, ідентифікацію та автентифікацію користувачів, ієрархічний контроль специфікацій доступу та захист первинної пам'яті [26].

У 1975 році Saltzer & Schroeder представили 8 принципів проектування та серію бажаних функцій з наміром захистити інформацію, що зберігається на комп'ютері, від несанкціонованого доступу та модифікації. На той час програмні додатки могли зберігати інформацію та одночасно використовуватися декількома користувачами. Ключовим викликом, який хотіли вирішити Saltzer & Schroeder, було питання множинного використання. Для додатків з користувачами, які не мають рівних повноважень, потрібна система для забезпечення бажаної структури повноважень у додатку [27].

Робота Saltzer & Schroeder стала дуже впливовою та застосовною до широкого спектру галузей, таких як забезпечення політик безпеки [28], оцінка архітектури безпеки Java [9] та мінімізація помилок, пов'язаних з користувачами, в безпеці інформаційних систем [30].

Однак лише в 1995 році принципи Saltzer & Schroeder вперше були застосовані до проектування API безпеки через Cryptlib [11]. Між 1995 та 2002 роками Gutmann адаптував роботу Saltzer & Schroeder для вирішення викликів безпеки та зручності використання при проектуванні криптографічного API [11–13]. Робота Gutmann відіграла інтегральну роль у впровадженні принципів проектування Saltzer & Schroeder у галузь проектування API безпеки [1, 10, 19, 23, 24, 32].

Еволюцію принципів Saltzer & Schroeder можна віднести на рахунок постійно змінного ландшафту кібербезпеки та викликів, які з цим приходять, оскільки саме ці виклики змушують принципи еволюціонувати.

Сьогодні ми спостерігаємо настання світу штучного інтелекту. З випуском великих мовних моделей (LLM), OpenAI розпочала гонку ШІ з невизначеною фінішною лінією. Тепер, змагаючись з конкурентами, такими як Google's PaLM та LaMDA, ми бачимо швидкий розвиток у цій галузі. Спільнота розробки програмного забезпечення проявила великий інтерес до цих досягнень, оскільки інтеграція інструментів генерування коду на основі ШІ, таких як ChatGPT та GitHub Copilot, може допомогти їм у багатьох різноманітних завданнях, таких як покращення процесу перегляду коду, надання пропозицій кодування, пропонування виправлень для дефектів у коді.

У майбутньому ці інструменти генерування коду на основі ШІ могли б допомогти в рефакторингу кодових баз великих, складних програмних додатків, покращенні читабельності та полегшенні підтримки з підтримкою документації, згенерованої ШІ [2, 5].

З усіма цими майбутніми змінами в індустрії програмного забезпечення, яку роль відіграють Saltzer & Schroeder у цьому світі ШІ? Чи достатньо їхніх принципів проектування безпеки? Якщо ні, то чому ні? Якщо вони достатні, як ми повинні використовувати їх для формування бачення на 2030 рік?

У цій статті ми оцінюємо здатність ChatGPT безпечно зберігати пароль та оцінюємо згенерований код відповідно до критеріїв Naiakshina для безпечного зберігання паролів [21]. Після цього ми підказуємо ChatGPT повторити завдання, але цього разу використовуючи критерії безпеки Naiakshina як список вимог. Нарешті, ми просимо ChatGPT оцінити свій згенерований код відповідно до принципів проектування безпеки Saltzer & Schroeder [27].

Мета цієї вправи полягає не тільки в розумінні можливостей ChatGPT у безпечному кодуванні та розумінні принципів безпеки, але також як крок у розумінні того, де в динаміці Розробник/ШІ можуть бути впроваджені Saltzer & Schroeder? Де в процесі розробки програмного забезпечення Saltzer & Schroeder були б найбільш ефективними? Якщо вони не ефективні, які недоліки? Чи можуть вони бути вирішені через адаптований набір принципів Saltzer & Schroeder? Чи достатньо Saltzer & Schroeder, чи це кінець дороги?

## 2. ПЕРЕДУМОВИ

### 2.1 Загальні висновки

Після випуску GitHub Copilot, ШІ-програміста для парного програмування, Bird et al. [2] вивчили процес парного програмування та те, як інтеграція GitHub Copilot змінила роль розробника. Bird et al. пояснює, як коли два розробники пишуть код разом, один бере на себе роль водія, пишучи код для призначеного завдання, тоді як інший працює як навігатор, направляючи та переглядаючи роботу водія. Однак Bird et al. виявили, що після впровадження GitHub Copilot роль розробників змінюється від написання коду до розуміння коду. Впровадження GitHub Copilot означає, що навичка перегляду коду стала рівною, якщо не більш важливою, ніж написання коду. Методи, якими розробники можуть оцінювати код, згенерований ШІ, ще не розроблені. Наразі згенерований код проходить той самий процес перегляду, що й код розробника [2, 5].

Щодо продуктивності, GitHub Copilot відомий тим, що допомагає розробникам адаптуватися до різних мов програмування та стилів написання [2]. Однак, що стосується якості коду, Yetiştiren et al. [33, 34] провели емпіричне дослідження для порівняння якості коду та правильності GitHub Copilot, ChatGPT та Amazon CodeWhisperer, використовуючи набір даних HumanEval [4], і виявили, що з точки зору правильності коду ChatGPT показав найкращі результати з правильними рішеннями для 65,2% задач набору даних HumanEval, за ним йде GitHub Copilot. Yetiştiren зазначив, що розробники повинні очікувати знайти деякі помилки з усіма цими інструментами, але ці помилки не настільки поширені, як виявлені "запахи коду" (code smells). Загалом було виявлено 13 "запахів коду" від трьох інструментів генерування коду на основі ШІ [33, 34].

Ernst et al. [5] коментують короткострокові та довгострокові ефекти використання AIDE (Середовища розробки, керовані штучним інтелектом) для вивчення програмування. З одного боку, інструменти як ChatGPT та GitHub Copilot дійсно можуть допомогти початківцю-розробнику вивчити мову програмування, пропонуючи пропозиції та допомагаючи з завданнями кодування. Це може здатися привабливим багатьом розробникам, які приєднуються до індустрії сьогодні, але з іншого боку, ці розробники можуть мати труднощі з повним розумінням того, чому запропонований фрагмент коду працює і як правильно інтегрувати його з їхньою існуючою кодовою базою [5].

Крім того, Codex від OpenAI становить виклик для викладачів та університетських модулів, оскільки він достатньо хороший, щоб перевершити багатьох студентів у модулях "Комп'ютерні науки 1" ступеня комп'ютерних наук. Студенти можуть почати думати, що якщо Codex краще програмує, ніж вони, навіщо їм турбуватися про вивчення програмування? Замість цього студенти почнуть зосереджуватися на інженерії підказок та вивченні того, як налаштовувати код, згенерований ШІ. Їхня роль змінюється від водія (автора коду) до навігатора (дизайнера завдань), але це має серйозні наслідки.

Багато студентів вперше знайомляться з практиками кодування та принципами проектування в університеті, тому впроваджуючи LLM як Codex, студенти можуть бути позбавлені можливості застосувати принципи проектування, які вони вивчають теоретично, до практичних застосувань, оскільки вони можуть попросити ChatGPT згенерувати код для них і втратять свою здатність до вирішення проблем та критичного мислення. Цей потенційний сценарій також зупиняє впровадження та еволюцію принципів проектування безпеки та практик безпечного кодування [3, 6, 7, 22, 27].

У недавньому дослідженні Lau et al. [17] було проведено опитування 20 інструкторів програмування, щоб зрозуміти, як вони планують адаптуватися до впровадження моделей ШІ. На короткострокову перспективу практики мають намір відмовляти від використання таких інструментів, але готуючись до майбутнього, деякі погодилися, що такий опір марний, і готові інтегрувати інструменти генерування коду на основі ШІ з їхніми існуючими програмами.

### 2.2 Наслідки для безпеки використання моделей ШІ

Останні роботи зробили кроки для розуміння наслідків для безпеки використання інструментів генерування коду на основі ШІ [14, 16, 25, 29, 31]. Pearce et al. [25] провели емпіричне дослідження для оцінки продуктивності GitHub Copilot проти підмножини Топ-25 найпоширеніших перерахувань слабкостей (CWE) MITRE. Результати з точки зору безпеки були невизначеними, але Pearce et al. зазначають, що GitHub Copilot навчений на наборі даних відкритого коду, тому розробники повинні очікувати помилки і тому їм радиться залишатися критичними та пильними щодо коду, згенерованого GitHub Copilot. Цікавий момент, згаданий Pearce et al., - це вплив часу на якість безпеки в програмному забезпеченні з відкритим кодом. Найкраща практика на момент написання може повільно стати поганою практикою, оскільки ландшафт кібербезпеки змінюється.

He et al. розробили нове завдання безпеки, яке називається контрольованим генеруванням коду, для якого вони пропонують SVEN - підхід на основі навчання з додатковим бінарним параметром, доданим поряд із підказкою. Через цей бінарний параметр He et al. можуть визначити процес зміцнення безпеки або тестування на стійкість. Подібно до Pearce et al. [25], SVEN оцінюється, використовуючи підмножину Топ-25 CWE MITRE. He et al. виявили, що SVEN досягає високого рівня контролю безпеки через їхнє новаторське завдання.

Hajipour et al. [14] розглядають виклик знаходження вразливостей безпеки в LLM Codex та CodeGen, використовуючи підхід інверсії з малою кількістю прикладів. У цьому підході моделі ШІ підказуються, використовуючи приклади вразливого коду та підтримуючі підказки, щоб побачити, чи генерує вона вразливий код. Як і з усіма дослідженнями, обговорюваними тут, Hajipour et al. [14] використовують CodeQL для оцінки безпеки згенерованого коду. В результаті їхнього дослідження вони показали, що їхній підхід здатний знайти тисячі вразливостей безпеки в моделях ШІ, але потрібно більше роботи для визначення кращої методології для ідентифікації підказок, які призводять до вразливостей безпеки [14].

Tony et al. [31] фактично використали фрагменти вразливого коду на свою користь, щоб допомогти оцінити здатність GPT-3 та Code LLM генерувати безпечний код. Вони представили LLMSecEval - набір даних із 150 підказок природною мовою з описами фрагментів коду, схильних до вразливостей, які можна побачити в Топ-25 найпоширеніших перерахуваннях слабкостей (CWE) MITRE. Кожна підказка з набору даних мала пов'язану з нею безпечну реалізацію для порівняння відповідей GPT-3 та Codex. Подібний підхід можна використати для оцінки наявності принципів проектування безпеки в коді, згенерованому ШІ.

## 3. КЕЙС-СТАДІ: БЕЗПЕЧНЕ ЗБЕРІГАННЯ ПАРОЛІВ З CHATGPT

Ми представляємо кейс-стаді безпечного зберігання пароля - добре відоме завдання безпеки, яке було широко вивчене академічною дослідницькою спільнотою [15, 16, 21]. Однак література...

---

## ПЕРЕКЛАД ВИКОНАНО

**Автори оригіналу**: Nikhil Patnaik, Joseph Hallett, Awais Rashid  
**Переклад українською**: Claude  
**Дата**: 2024  

### Примітки до перекладу:

1. **Security-by-design** перекладено як "безпека за замовчуванням" для кращого розуміння в українському контексті
2. **Large Language Models (LLMs)** залишено як "великі мовні моделі" з абревіатурою в дужках
3. **API** залишено без перекладу як загальноприйнятий термін
4. Назви продуктів (ChatGPT, GitHub Copilot, Multics) залишено в оригінальному написанні
5. Прізвища дослідників (Saltzer, Schroeder, Gutmann, Naiakshina) залишено в оригінальній транскрипції
6. **Code smells** перекладено як "запахи коду" - усталений термін в українській ІТ-спільноті
7. **CWE (Common Weakness Enumerations)** - залишено з поясненням українською



